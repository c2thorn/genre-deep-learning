{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "songs = []\n",
    "\n",
    "full_genres = [['soundtrack'],\n",
    "                ['jazz'],\n",
    "                ['classical'],\n",
    "               ['metal'],\n",
    "               ['indietronica','wave','synth'],\n",
    "               ['downtempo','trip hop'],\n",
    "               ['edm','electronica','idm','dubstep','techno'],\n",
    "               ['house'],\n",
    "               ['r&b','rnb','soul'],\n",
    "               ['rock'],\n",
    "               ['hip hop','rap','trap','hiphop'],\n",
    "               ['pop']]\n",
    "\n",
    "def loadSongList(filename):\n",
    "    with open(filename, 'r') as myfile:\n",
    "        global songs\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "        song_data  = json.loads(data)\n",
    "        songs = song_data    \n",
    "\n",
    "def loadDataFrame(filename):\n",
    "    global df\n",
    "    df = pd.read_pickle(filename)\n",
    "\n",
    "def loadModel(filename):\n",
    "    global model\n",
    "    model = load_model(filename)\n",
    "\n",
    "def saveModel(filename):\n",
    "    model.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Without My Heart', 'spotify:track:2mQJklbyeg532eqvoYgsRl', 'Tyrese', 'Black Rose', [8, 'r&b']]\n",
      "['Blame It', 'spotify:track:08uGhvS5MfBk7crUCpnjva', 'Jamie Foxx', 'Intuition', [8, 'r&b']]\n",
      "['Real Love', 'spotify:track:3XG801WWhqC753dekEBkMt', 'Mary J. Blige', \"What's The 411?\", [8, 'r&b']]\n",
      "['AM // Radio', 'spotify:track:3cR19PDGb6w48V96kMaZOf', 'Earl Sweatshirt', \"I Don't Like Shit, I Don't Go Outside: An Album by Earl Sweatshirt\", [10, 'hip hop']]\n",
      "['X (with 2 Chainz & Saudi)', 'spotify:track:4LmAnpjlhWTahvRkYR8xJa', 'ScHoolboy Q', 'Black Panther The Album Music From And Inspired By', [10, 'hip hop']]\n",
      "['Opps (with Yugen Blakrok)', 'spotify:track:7bUcBztfGqO7cSI2gMZeCI', 'Vince Staples', 'Black Panther The Album Music From And Inspired By', [10, 'hip hop']]\n",
      "['I Am', 'spotify:track:0DJBgBiYeSn6n1AXAkFVE8', 'Jorja Smith', 'Black Panther The Album Music From And Inspired By', [8, 'r&b']]\n",
      "['Bloody Waters (with Anderson .Paak & James Blake)', 'spotify:track:4KXwFI9pgJLpUIAc9oSL8j', 'Ab-Soul', 'Black Panther The Album Music From And Inspired By', [10, 'hip hop']]\n",
      "[\"King's Dead (with Kendrick Lamar, Future & James Blake)\", 'spotify:track:1eLSF6HfrRA0AsNmTkUlKx', 'Jay Rock', 'Black Panther The Album Music From And Inspired By', [10, 'hip hop']]\n",
      "['Big Shot (with Travis Scott)', 'spotify:track:5cXg9IQS34FzLVdHhp7hu7', 'Kendrick Lamar', 'Black Panther The Album Music From And Inspired By', [10, 'hip hop']]\n",
      "9606\n",
      "9606\n"
     ]
    }
   ],
   "source": [
    "loadSongList('song_list_final.txt')\n",
    "loadDataFrame('dataframe.pkl')\n",
    "\n",
    "for i in range(10):\n",
    "    print(songs[i])\n",
    "df[:10]\n",
    "\n",
    "print(len(songs))\n",
    "print(len(df[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.51485</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.74700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.593180</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.27130</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.880260</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.759</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.27825</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.475065</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.37660</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.411825</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.42400</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.655130</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.34055</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.13700</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.640390</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.28765</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.368960</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.501</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.44300</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.17600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.902065</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.23320</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.408480</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.45270</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.00763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.650435</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  loudness  speechiness  acousticness  \\\n",
       "0         0.401   0.393   0.51485       0.0520       0.74700   \n",
       "1         0.673   0.614   0.27130       0.1030       0.07820   \n",
       "2         0.759   0.789   0.27825       0.0744       0.11200   \n",
       "3         0.470   0.389   0.37660       0.0725       0.16200   \n",
       "4         0.764   0.468   0.42400       0.2740       0.02250   \n",
       "5         0.714   0.775   0.34055       0.3270       0.13700   \n",
       "6         0.542   0.581   0.28765       0.2710       0.12500   \n",
       "7         0.501   0.606   0.44300       0.4450       0.17600   \n",
       "8         0.560   0.733   0.23320       0.3220       0.00111   \n",
       "9         0.854   0.484   0.45270       0.2130       0.00763   \n",
       "\n",
       "   instrumentalness  liveness  valence     tempo  genre  \n",
       "0          0.000000    0.1210    0.279  0.593180    8.0  \n",
       "1          0.000000    0.1390    0.362  0.880260    8.0  \n",
       "2          0.000183    0.0526    0.811  0.475065    8.0  \n",
       "3          0.007180    0.2250    0.524  0.411825   10.0  \n",
       "4          0.000000    0.2600    0.360  0.655130   10.0  \n",
       "5          0.000032    0.3960    0.840  0.640390   10.0  \n",
       "6          0.000080    0.1850    0.298  0.368960    8.0  \n",
       "7          0.000000    0.1580    0.194  0.902065   10.0  \n",
       "8          0.000000    0.1620    0.413  0.408480   10.0  \n",
       "9          0.000000    0.0970    0.302  0.650435   10.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = df[:]\n",
    "\n",
    "processed_data['loudness'] = processed_data['loudness']/-20\n",
    "processed_data['tempo'] = processed_data['tempo']/200\n",
    "processed_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is 8645\n",
      "Number of testing samples is 961\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
    "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.531      0.586      0.3005     0.21       0.28       0.\n",
      "  0.0824     0.785      0.418555  ]\n",
      " [0.724      0.95       0.2833     0.0727     0.0028     0.0408\n",
      "  0.174      0.725      0.62007   ]\n",
      " [0.794      0.868      0.2821     0.0547     0.688      0.882\n",
      "  0.0971     0.455      0.57499   ]\n",
      " [0.886      0.585      0.1065     0.0493     0.0326     0.00000485\n",
      "  0.0882     0.793      0.725035  ]\n",
      " [0.887      0.633      0.39905    0.183      0.00729    0.0000286\n",
      "  0.257      0.429      0.519665  ]\n",
      " [0.486      0.563      0.6132     0.0334     0.0186     0.0000477\n",
      "  0.074      0.678      0.52769   ]\n",
      " [0.426      0.408      0.47095    0.0524     0.771      0.00000788\n",
      "  0.394      0.528      0.381545  ]\n",
      " [0.316      0.927      0.30225    0.0709     0.209      0.867\n",
      "  0.102      0.576      0.848335  ]\n",
      " [0.523      0.364      0.6769     0.0645     0.614      0.731\n",
      "  0.0816     0.795      0.58146   ]\n",
      " [0.89       0.633      0.27375    0.168      0.0232     0.000343\n",
      "  0.0993     0.425      0.69974   ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Separate data and one-hot encode the output\n",
    "# Note: We're also turning the data into numpy arrays, in order to train the model in Keras\n",
    "features = np.array(train_data.drop('genre', axis=1))\n",
    "targets = np.array(keras.utils.to_categorical(train_data['genre'], len(full_genres)))\n",
    "features_test = np.array(test_data.drop('genre', axis=1))\n",
    "targets_test = np.array(keras.utils.to_categorical(test_data['genre'], len(full_genres)))\n",
    "\n",
    "print(features[:10])\n",
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 1000)              10000     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 12)                12012     \n",
      "=================================================================\n",
      "Total params: 4,026,012\n",
      "Trainable params: 4,026,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "# model.add(Dense(2048, activation='relu', input_shape=(9,)))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "\n",
    "model.add(Dense(1000, activation='relu', input_shape=(9,)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dropout(.2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(len(full_genres), activation='softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6916 samples, validate on 1729 samples\n",
      "Epoch 1/200\n",
      "6916/6916 [==============================] - 8s 1ms/step - loss: 2.4353 - acc: 0.1575 - val_loss: 2.2886 - val_acc: 0.2163\n",
      "Epoch 2/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 2.2632 - acc: 0.2324 - val_loss: 2.1159 - val_acc: 0.2782\n",
      "Epoch 3/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 2.0650 - acc: 0.2817 - val_loss: 1.9910 - val_acc: 0.3112\n",
      "Epoch 4/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.9506 - acc: 0.3135 - val_loss: 1.8713 - val_acc: 0.2961\n",
      "Epoch 5/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.8622 - acc: 0.3156 - val_loss: 1.8013 - val_acc: 0.3482\n",
      "Epoch 6/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.7898 - acc: 0.3447 - val_loss: 1.7528 - val_acc: 0.3482\n",
      "Epoch 7/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.7279 - acc: 0.3603 - val_loss: 1.6696 - val_acc: 0.4205\n",
      "Epoch 8/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.6690 - acc: 0.4096 - val_loss: 1.6191 - val_acc: 0.4396\n",
      "Epoch 9/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.6047 - acc: 0.4287 - val_loss: 1.5929 - val_acc: 0.4436\n",
      "Epoch 10/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.5938 - acc: 0.4365 - val_loss: 1.6002 - val_acc: 0.4419\n",
      "Epoch 11/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.5936 - acc: 0.4387 - val_loss: 1.5711 - val_acc: 0.4546\n",
      "Epoch 12/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.5677 - acc: 0.4422 - val_loss: 1.5423 - val_acc: 0.4656\n",
      "Epoch 13/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.5392 - acc: 0.4530 - val_loss: 1.5436 - val_acc: 0.4662\n",
      "Epoch 14/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.5324 - acc: 0.4555 - val_loss: 1.5433 - val_acc: 0.4546\n",
      "Epoch 15/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.5168 - acc: 0.4636 - val_loss: 1.5355 - val_acc: 0.4667\n",
      "Epoch 16/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.5180 - acc: 0.4594 - val_loss: 1.5166 - val_acc: 0.4743\n",
      "Epoch 17/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.5027 - acc: 0.4708 - val_loss: 1.5209 - val_acc: 0.4719\n",
      "Epoch 18/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.5008 - acc: 0.4662 - val_loss: 1.5123 - val_acc: 0.4719\n",
      "Epoch 19/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4974 - acc: 0.4652 - val_loss: 1.5009 - val_acc: 0.4847\n",
      "Epoch 20/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4887 - acc: 0.4669 - val_loss: 1.4989 - val_acc: 0.4795\n",
      "Epoch 21/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4816 - acc: 0.4754 - val_loss: 1.4872 - val_acc: 0.4783\n",
      "Epoch 22/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4739 - acc: 0.4793 - val_loss: 1.4833 - val_acc: 0.4881\n",
      "Epoch 23/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4699 - acc: 0.4770 - val_loss: 1.4817 - val_acc: 0.4870\n",
      "Epoch 24/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4668 - acc: 0.4798 - val_loss: 1.4899 - val_acc: 0.4824\n",
      "Epoch 25/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4527 - acc: 0.4845 - val_loss: 1.4813 - val_acc: 0.4933\n",
      "Epoch 26/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4482 - acc: 0.4851 - val_loss: 1.4766 - val_acc: 0.4939\n",
      "Epoch 27/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.4423 - acc: 0.4879 - val_loss: 1.4714 - val_acc: 0.4968\n",
      "Epoch 28/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4375 - acc: 0.4881 - val_loss: 1.4804 - val_acc: 0.4876\n",
      "Epoch 29/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4339 - acc: 0.4907 - val_loss: 1.4727 - val_acc: 0.4997\n",
      "Epoch 30/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4341 - acc: 0.4866 - val_loss: 1.4696 - val_acc: 0.4864\n",
      "Epoch 31/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4303 - acc: 0.4915 - val_loss: 1.4627 - val_acc: 0.4945\n",
      "Epoch 32/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4310 - acc: 0.4857 - val_loss: 1.4632 - val_acc: 0.4876\n",
      "Epoch 33/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4225 - acc: 0.4866 - val_loss: 1.4560 - val_acc: 0.5038\n",
      "Epoch 34/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4097 - acc: 0.4948 - val_loss: 1.4675 - val_acc: 0.4910\n",
      "Epoch 35/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4106 - acc: 0.4873 - val_loss: 1.4708 - val_acc: 0.5032\n",
      "Epoch 36/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4159 - acc: 0.4873 - val_loss: 1.4628 - val_acc: 0.4910\n",
      "Epoch 37/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.4054 - acc: 0.4918 - val_loss: 1.4590 - val_acc: 0.4974\n",
      "Epoch 38/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.4097 - acc: 0.4903 - val_loss: 1.4517 - val_acc: 0.4893\n",
      "Epoch 39/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3987 - acc: 0.5038 - val_loss: 1.4358 - val_acc: 0.5067\n",
      "Epoch 40/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3894 - acc: 0.5039 - val_loss: 1.4453 - val_acc: 0.5003\n",
      "Epoch 41/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3869 - acc: 0.4994 - val_loss: 1.4332 - val_acc: 0.4997\n",
      "Epoch 42/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3813 - acc: 0.5001 - val_loss: 1.4383 - val_acc: 0.5020\n",
      "Epoch 43/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3780 - acc: 0.5029 - val_loss: 1.4332 - val_acc: 0.5014\n",
      "Epoch 44/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3784 - acc: 0.5022 - val_loss: 1.4322 - val_acc: 0.5026\n",
      "Epoch 45/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3664 - acc: 0.5119 - val_loss: 1.4457 - val_acc: 0.4951\n",
      "Epoch 46/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3696 - acc: 0.5107 - val_loss: 1.4328 - val_acc: 0.5049\n",
      "Epoch 47/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3664 - acc: 0.5121 - val_loss: 1.4291 - val_acc: 0.5049\n",
      "Epoch 48/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3608 - acc: 0.5098 - val_loss: 1.4295 - val_acc: 0.5067\n",
      "Epoch 49/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3643 - acc: 0.5111 - val_loss: 1.4298 - val_acc: 0.5078\n",
      "Epoch 50/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3594 - acc: 0.5077 - val_loss: 1.4214 - val_acc: 0.5136\n",
      "Epoch 51/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3510 - acc: 0.5119 - val_loss: 1.4361 - val_acc: 0.5043\n",
      "Epoch 52/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3497 - acc: 0.5132 - val_loss: 1.4283 - val_acc: 0.5038\n",
      "Epoch 53/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3469 - acc: 0.5175 - val_loss: 1.4237 - val_acc: 0.5061\n",
      "Epoch 54/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3342 - acc: 0.5174 - val_loss: 1.4220 - val_acc: 0.5020\n",
      "Epoch 55/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3328 - acc: 0.5214 - val_loss: 1.4174 - val_acc: 0.5020\n",
      "Epoch 56/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3382 - acc: 0.5145 - val_loss: 1.4174 - val_acc: 0.5101\n",
      "Epoch 57/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3266 - acc: 0.5211 - val_loss: 1.4227 - val_acc: 0.5067\n",
      "Epoch 58/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3264 - acc: 0.5202 - val_loss: 1.4205 - val_acc: 0.5107\n",
      "Epoch 59/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3297 - acc: 0.5267 - val_loss: 1.4224 - val_acc: 0.5072\n",
      "Epoch 60/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3274 - acc: 0.5208 - val_loss: 1.4190 - val_acc: 0.5113\n",
      "Epoch 61/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3209 - acc: 0.5243 - val_loss: 1.4331 - val_acc: 0.5049\n",
      "Epoch 62/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3199 - acc: 0.5202 - val_loss: 1.4223 - val_acc: 0.5032\n",
      "Epoch 63/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3140 - acc: 0.5243 - val_loss: 1.4211 - val_acc: 0.5147\n",
      "Epoch 64/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3163 - acc: 0.5204 - val_loss: 1.4273 - val_acc: 0.5095\n",
      "Epoch 65/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3109 - acc: 0.5237 - val_loss: 1.4196 - val_acc: 0.5038\n",
      "Epoch 66/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.3086 - acc: 0.5250 - val_loss: 1.4095 - val_acc: 0.5055\n",
      "Epoch 67/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3017 - acc: 0.5291 - val_loss: 1.4223 - val_acc: 0.5038\n",
      "Epoch 68/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3033 - acc: 0.5270 - val_loss: 1.4229 - val_acc: 0.5020\n",
      "Epoch 69/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.3007 - acc: 0.5346 - val_loss: 1.4256 - val_acc: 0.5038\n",
      "Epoch 70/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2968 - acc: 0.5260 - val_loss: 1.4109 - val_acc: 0.5095\n",
      "Epoch 71/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2977 - acc: 0.5321 - val_loss: 1.4125 - val_acc: 0.5130\n",
      "Epoch 72/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2910 - acc: 0.5296 - val_loss: 1.4187 - val_acc: 0.5078\n",
      "Epoch 73/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2886 - acc: 0.5298 - val_loss: 1.4220 - val_acc: 0.5095\n",
      "Epoch 74/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2829 - acc: 0.5357 - val_loss: 1.4149 - val_acc: 0.5072\n",
      "Epoch 75/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2768 - acc: 0.5353 - val_loss: 1.4341 - val_acc: 0.4974\n",
      "Epoch 76/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2822 - acc: 0.5318 - val_loss: 1.4151 - val_acc: 0.5072\n",
      "Epoch 77/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2753 - acc: 0.5335 - val_loss: 1.4212 - val_acc: 0.4968\n",
      "Epoch 78/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2638 - acc: 0.5411 - val_loss: 1.4258 - val_acc: 0.5032\n",
      "Epoch 79/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2676 - acc: 0.5422 - val_loss: 1.4284 - val_acc: 0.4962\n",
      "Epoch 80/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2593 - acc: 0.5414 - val_loss: 1.4254 - val_acc: 0.5095\n",
      "Epoch 81/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2566 - acc: 0.5434 - val_loss: 1.4167 - val_acc: 0.5090\n",
      "Epoch 82/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2514 - acc: 0.5461 - val_loss: 1.4240 - val_acc: 0.5095\n",
      "Epoch 83/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2518 - acc: 0.5457 - val_loss: 1.4290 - val_acc: 0.4997\n",
      "Epoch 84/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2470 - acc: 0.5499 - val_loss: 1.4281 - val_acc: 0.5101\n",
      "Epoch 85/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2391 - acc: 0.5477 - val_loss: 1.4137 - val_acc: 0.5090\n",
      "Epoch 86/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2398 - acc: 0.5466 - val_loss: 1.4201 - val_acc: 0.5072\n",
      "Epoch 87/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2453 - acc: 0.5463 - val_loss: 1.4302 - val_acc: 0.4986\n",
      "Epoch 88/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2392 - acc: 0.5470 - val_loss: 1.4244 - val_acc: 0.5095\n",
      "Epoch 89/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2281 - acc: 0.5557 - val_loss: 1.4320 - val_acc: 0.5067\n",
      "Epoch 90/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2319 - acc: 0.5518 - val_loss: 1.4341 - val_acc: 0.5084\n",
      "Epoch 91/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2316 - acc: 0.5552 - val_loss: 1.4357 - val_acc: 0.5049\n",
      "Epoch 92/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2149 - acc: 0.5516 - val_loss: 1.4409 - val_acc: 0.4991\n",
      "Epoch 93/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2183 - acc: 0.5499 - val_loss: 1.4294 - val_acc: 0.5078\n",
      "Epoch 94/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2158 - acc: 0.5567 - val_loss: 1.4300 - val_acc: 0.5055\n",
      "Epoch 95/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2127 - acc: 0.5588 - val_loss: 1.4327 - val_acc: 0.5061\n",
      "Epoch 96/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2123 - acc: 0.5561 - val_loss: 1.4319 - val_acc: 0.5020\n",
      "Epoch 97/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2016 - acc: 0.5651 - val_loss: 1.4404 - val_acc: 0.5067\n",
      "Epoch 98/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.2020 - acc: 0.5616 - val_loss: 1.4395 - val_acc: 0.4899\n",
      "Epoch 99/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2062 - acc: 0.5602 - val_loss: 1.4348 - val_acc: 0.5067\n",
      "Epoch 100/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1971 - acc: 0.5557 - val_loss: 1.4337 - val_acc: 0.5113\n",
      "Epoch 101/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2022 - acc: 0.5593 - val_loss: 1.4546 - val_acc: 0.5107\n",
      "Epoch 102/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.2029 - acc: 0.5561 - val_loss: 1.4519 - val_acc: 0.4986\n",
      "Epoch 103/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.1947 - acc: 0.5625 - val_loss: 1.4448 - val_acc: 0.4928\n",
      "Epoch 104/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.1837 - acc: 0.5682 - val_loss: 1.4526 - val_acc: 0.5032\n",
      "Epoch 105/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1804 - acc: 0.5669 - val_loss: 1.4456 - val_acc: 0.5009\n",
      "Epoch 106/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.1721 - acc: 0.5684 - val_loss: 1.4406 - val_acc: 0.4997\n",
      "Epoch 107/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.1660 - acc: 0.5719 - val_loss: 1.4355 - val_acc: 0.5055\n",
      "Epoch 108/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1696 - acc: 0.5690 - val_loss: 1.4575 - val_acc: 0.5043\n",
      "Epoch 109/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1763 - acc: 0.5706 - val_loss: 1.4432 - val_acc: 0.5147\n",
      "Epoch 110/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1675 - acc: 0.5729 - val_loss: 1.4489 - val_acc: 0.5090\n",
      "Epoch 111/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1493 - acc: 0.5836 - val_loss: 1.4591 - val_acc: 0.5038\n",
      "Epoch 112/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1510 - acc: 0.5755 - val_loss: 1.4507 - val_acc: 0.5072\n",
      "Epoch 113/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1478 - acc: 0.5833 - val_loss: 1.4449 - val_acc: 0.5020\n",
      "Epoch 114/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.1445 - acc: 0.5787 - val_loss: 1.4666 - val_acc: 0.4980\n",
      "Epoch 115/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1472 - acc: 0.5776 - val_loss: 1.4476 - val_acc: 0.5055\n",
      "Epoch 116/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1392 - acc: 0.5791 - val_loss: 1.4622 - val_acc: 0.5072\n",
      "Epoch 117/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1257 - acc: 0.5844 - val_loss: 1.4638 - val_acc: 0.5026\n",
      "Epoch 118/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1226 - acc: 0.5814 - val_loss: 1.4568 - val_acc: 0.5049\n",
      "Epoch 119/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1267 - acc: 0.5843 - val_loss: 1.4586 - val_acc: 0.5119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1211 - acc: 0.5875 - val_loss: 1.4659 - val_acc: 0.4974\n",
      "Epoch 121/200\n",
      "6916/6916 [==============================] - 0s 19us/step - loss: 1.1215 - acc: 0.5863 - val_loss: 1.4846 - val_acc: 0.4939\n",
      "Epoch 122/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1220 - acc: 0.5857 - val_loss: 1.5181 - val_acc: 0.4887\n",
      "Epoch 123/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1311 - acc: 0.5817 - val_loss: 1.4696 - val_acc: 0.5049\n",
      "Epoch 124/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.1076 - acc: 0.5881 - val_loss: 1.4743 - val_acc: 0.4945\n",
      "Epoch 125/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1000 - acc: 0.5998 - val_loss: 1.4828 - val_acc: 0.5003\n",
      "Epoch 126/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.0988 - acc: 0.6021 - val_loss: 1.4760 - val_acc: 0.5026\n",
      "Epoch 127/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.1045 - acc: 0.5918 - val_loss: 1.4851 - val_acc: 0.4991\n",
      "Epoch 128/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.0924 - acc: 0.6037 - val_loss: 1.4794 - val_acc: 0.4986\n",
      "Epoch 129/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0803 - acc: 0.5985 - val_loss: 1.4822 - val_acc: 0.5049\n",
      "Epoch 130/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0746 - acc: 0.6041 - val_loss: 1.5014 - val_acc: 0.5061\n",
      "Epoch 131/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0840 - acc: 0.5967 - val_loss: 1.4863 - val_acc: 0.5020\n",
      "Epoch 132/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.0605 - acc: 0.6073 - val_loss: 1.4760 - val_acc: 0.5014\n",
      "Epoch 133/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0702 - acc: 0.6103 - val_loss: 1.5199 - val_acc: 0.5009\n",
      "Epoch 134/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0664 - acc: 0.6045 - val_loss: 1.4972 - val_acc: 0.4881\n",
      "Epoch 135/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0575 - acc: 0.6139 - val_loss: 1.5079 - val_acc: 0.5032\n",
      "Epoch 136/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.0516 - acc: 0.6151 - val_loss: 1.5111 - val_acc: 0.4974\n",
      "Epoch 137/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0559 - acc: 0.6090 - val_loss: 1.5035 - val_acc: 0.5165\n",
      "Epoch 138/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0464 - acc: 0.6171 - val_loss: 1.4987 - val_acc: 0.5032\n",
      "Epoch 139/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0373 - acc: 0.6242 - val_loss: 1.5139 - val_acc: 0.4974\n",
      "Epoch 140/200\n",
      "6916/6916 [==============================] - 0s 19us/step - loss: 1.0454 - acc: 0.6204 - val_loss: 1.5197 - val_acc: 0.5055\n",
      "Epoch 141/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0365 - acc: 0.6207 - val_loss: 1.5151 - val_acc: 0.5043\n",
      "Epoch 142/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0335 - acc: 0.6203 - val_loss: 1.5164 - val_acc: 0.5026\n",
      "Epoch 143/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0147 - acc: 0.6248 - val_loss: 1.5456 - val_acc: 0.4997\n",
      "Epoch 144/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0239 - acc: 0.6232 - val_loss: 1.5359 - val_acc: 0.4928\n",
      "Epoch 145/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0139 - acc: 0.6254 - val_loss: 1.5234 - val_acc: 0.4951\n",
      "Epoch 146/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0185 - acc: 0.6274 - val_loss: 1.5477 - val_acc: 0.4945\n",
      "Epoch 147/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 1.0050 - acc: 0.6233 - val_loss: 1.5683 - val_acc: 0.4986\n",
      "Epoch 148/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0118 - acc: 0.6280 - val_loss: 1.5465 - val_acc: 0.4951\n",
      "Epoch 149/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0033 - acc: 0.6294 - val_loss: 1.5636 - val_acc: 0.5147\n",
      "Epoch 150/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 1.0031 - acc: 0.6278 - val_loss: 1.5343 - val_acc: 0.4922\n",
      "Epoch 151/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9917 - acc: 0.6313 - val_loss: 1.5525 - val_acc: 0.5049\n",
      "Epoch 152/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9877 - acc: 0.6293 - val_loss: 1.5571 - val_acc: 0.4910\n",
      "Epoch 153/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9682 - acc: 0.6416 - val_loss: 1.5645 - val_acc: 0.4980\n",
      "Epoch 154/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9730 - acc: 0.6348 - val_loss: 1.5666 - val_acc: 0.5003\n",
      "Epoch 155/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9651 - acc: 0.6424 - val_loss: 1.5682 - val_acc: 0.4997\n",
      "Epoch 156/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9631 - acc: 0.6481 - val_loss: 1.5877 - val_acc: 0.4841\n",
      "Epoch 157/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9561 - acc: 0.6439 - val_loss: 1.5975 - val_acc: 0.5032\n",
      "Epoch 158/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9477 - acc: 0.6463 - val_loss: 1.5796 - val_acc: 0.4957\n",
      "Epoch 159/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9468 - acc: 0.6517 - val_loss: 1.5934 - val_acc: 0.5061\n",
      "Epoch 160/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9498 - acc: 0.6457 - val_loss: 1.5851 - val_acc: 0.5049\n",
      "Epoch 161/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9389 - acc: 0.6570 - val_loss: 1.6046 - val_acc: 0.5043\n",
      "Epoch 162/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9364 - acc: 0.6564 - val_loss: 1.6089 - val_acc: 0.5049\n",
      "Epoch 163/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9312 - acc: 0.6520 - val_loss: 1.5899 - val_acc: 0.5038\n",
      "Epoch 164/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9235 - acc: 0.6615 - val_loss: 1.5996 - val_acc: 0.4991\n",
      "Epoch 165/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9166 - acc: 0.6602 - val_loss: 1.6031 - val_acc: 0.5009\n",
      "Epoch 166/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9189 - acc: 0.6589 - val_loss: 1.6142 - val_acc: 0.5003\n",
      "Epoch 167/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9205 - acc: 0.6540 - val_loss: 1.6298 - val_acc: 0.4968\n",
      "Epoch 168/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9005 - acc: 0.6666 - val_loss: 1.6362 - val_acc: 0.5101\n",
      "Epoch 169/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9030 - acc: 0.6663 - val_loss: 1.6658 - val_acc: 0.4910\n",
      "Epoch 170/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9014 - acc: 0.6657 - val_loss: 1.6513 - val_acc: 0.4968\n",
      "Epoch 171/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8921 - acc: 0.6674 - val_loss: 1.6415 - val_acc: 0.5003\n",
      "Epoch 172/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9090 - acc: 0.6631 - val_loss: 1.6914 - val_acc: 0.4968\n",
      "Epoch 173/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.9037 - acc: 0.6667 - val_loss: 1.6406 - val_acc: 0.4986\n",
      "Epoch 174/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.9133 - acc: 0.6599 - val_loss: 1.6596 - val_acc: 0.5003\n",
      "Epoch 175/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8939 - acc: 0.6703 - val_loss: 1.6367 - val_acc: 0.4910\n",
      "Epoch 176/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8819 - acc: 0.6664 - val_loss: 1.6510 - val_acc: 0.5038\n",
      "Epoch 177/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8720 - acc: 0.6763 - val_loss: 1.6534 - val_acc: 0.4991\n",
      "Epoch 178/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8761 - acc: 0.6726 - val_loss: 1.6776 - val_acc: 0.5026\n",
      "Epoch 179/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8533 - acc: 0.6786 - val_loss: 1.6772 - val_acc: 0.4962\n",
      "Epoch 180/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.8555 - acc: 0.6816 - val_loss: 1.6930 - val_acc: 0.4986\n",
      "Epoch 181/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.8368 - acc: 0.6887 - val_loss: 1.6965 - val_acc: 0.4980\n",
      "Epoch 182/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8402 - acc: 0.6832 - val_loss: 1.7047 - val_acc: 0.5009\n",
      "Epoch 183/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8326 - acc: 0.6875 - val_loss: 1.6891 - val_acc: 0.4986\n",
      "Epoch 184/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8326 - acc: 0.6887 - val_loss: 1.7113 - val_acc: 0.4986\n",
      "Epoch 185/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8167 - acc: 0.6854 - val_loss: 1.7182 - val_acc: 0.5009\n",
      "Epoch 186/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8362 - acc: 0.6917 - val_loss: 1.7484 - val_acc: 0.5020\n",
      "Epoch 187/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8168 - acc: 0.6984 - val_loss: 1.7367 - val_acc: 0.4991\n",
      "Epoch 188/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.8226 - acc: 0.6901 - val_loss: 1.7309 - val_acc: 0.4922\n",
      "Epoch 189/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8397 - acc: 0.6825 - val_loss: 1.7346 - val_acc: 0.4951\n",
      "Epoch 190/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8152 - acc: 0.6881 - val_loss: 1.7226 - val_acc: 0.5061\n",
      "Epoch 191/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.8125 - acc: 0.6955 - val_loss: 1.7299 - val_acc: 0.4991\n",
      "Epoch 192/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8059 - acc: 0.7008 - val_loss: 1.7818 - val_acc: 0.4997\n",
      "Epoch 193/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.8129 - acc: 0.7007 - val_loss: 1.7205 - val_acc: 0.4986\n",
      "Epoch 194/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.7942 - acc: 0.7084 - val_loss: 1.7433 - val_acc: 0.5020\n",
      "Epoch 195/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.7937 - acc: 0.7071 - val_loss: 1.7715 - val_acc: 0.4916\n",
      "Epoch 196/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.7737 - acc: 0.7072 - val_loss: 1.7432 - val_acc: 0.5003\n",
      "Epoch 197/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.7760 - acc: 0.7127 - val_loss: 1.7879 - val_acc: 0.4957\n",
      "Epoch 198/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.7627 - acc: 0.7118 - val_loss: 1.8078 - val_acc: 0.5009\n",
      "Epoch 199/200\n",
      "6916/6916 [==============================] - 0s 21us/step - loss: 0.7730 - acc: 0.7104 - val_loss: 1.7813 - val_acc: 0.5078\n",
      "Epoch 200/200\n",
      "6916/6916 [==============================] - 0s 20us/step - loss: 0.7563 - acc: 0.7186 - val_loss: 1.8287 - val_acc: 0.5090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6f74c4b70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "# model.fit(features, targets, epochs=200, batch_size=1000, verbose=1)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.best.h5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(features, targets, batch_size=3000, epochs=200,\n",
    "          validation_split=0.2, \n",
    "#           callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveModel('myModel.h5')\n",
    "# loadModel('myModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8645/8645 [==============================] - 1s 75us/step\n",
      "\n",
      " Training Accuracy: 0.7367264314701683\n",
      "961/961 [==============================] - 0s 73us/step\n",
      "\n",
      " Testing Accuracy: 0.5119667013527576\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(features, targets)\n",
    "print(\"\\n Training Accuracy:\", score[1])\n",
    "score = model.evaluate(features_test, targets_test)\n",
    "print(\"\\n Testing Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>1st guess</th>\n",
       "      <th>2nd guess</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Am</td>\n",
       "      <td>Jorja Smith</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.64</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>r&amp;b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eye 2 Eye</td>\n",
       "      <td>Huncho Jack</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.796</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>edm</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How U Feel</td>\n",
       "      <td>Huncho Jack</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.715</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>pop</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CINEMA 2</td>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.645</td>\n",
       "      <td>house</td>\n",
       "      <td>edm</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Piano Concerto No.3 In C, Op.26: 1. Andante - ...</td>\n",
       "      <td>Sergei Prokofiev</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Piano Concerto No.3 In C, Op.26: 2. Tema con v...</td>\n",
       "      <td>Sergei Prokofiev</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.734</td>\n",
       "      <td>jazz</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Piano Concerto in G Major, M. 83: 2. Adagio assai</td>\n",
       "      <td>Maurice Ravel</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.189</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.66</td>\n",
       "      <td>classical</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaspard de la nuit, M.55: Scarbo</td>\n",
       "      <td>Maurice Ravel</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1.726</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.332</td>\n",
       "      <td>classical</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12 Sonates en trio, Op. 1, Sonate No. 2 in E M...</td>\n",
       "      <td>Antonio Vivaldi</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.675</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lush</td>\n",
       "      <td>Four Tet</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.7</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>indietronica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Packs</td>\n",
       "      <td>The Underachievers</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.8</td>\n",
       "      <td>jazz</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Meeker Warm Energy</td>\n",
       "      <td>Lone</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>house</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Begin To Begin</td>\n",
       "      <td>Lone</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.58</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jaded</td>\n",
       "      <td>Lone</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.6</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>indietronica</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pink Cloud</td>\n",
       "      <td>Little Dragon</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.773</td>\n",
       "      <td>indietronica</td>\n",
       "      <td>pop</td>\n",
       "      <td>indietronica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Truth</td>\n",
       "      <td>Kamasi Washington</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.83</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>edm</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Belly of the Beast (feat. Chronixx)</td>\n",
       "      <td>Joey Bada$$</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.454</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O.C.B.</td>\n",
       "      <td>Joey Bada$$</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.383</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Drum</td>\n",
       "      <td>Slow Magic</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.635</td>\n",
       "      <td>house</td>\n",
       "      <td>edm</td>\n",
       "      <td>indietronica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What Happens</td>\n",
       "      <td>A$AP Mob</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.317</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BANK</td>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.643</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>indietronica</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Stardust (Intro)</td>\n",
       "      <td>ZHU</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.92</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>edm</td>\n",
       "      <td>edm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Will I See You Again</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.457</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fake Porcelain</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.73</td>\n",
       "      <td>pop</td>\n",
       "      <td>indietronica</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Memories From 1968</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.872</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bye Bye</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.761</td>\n",
       "      <td>1.018</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gotta Go</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.455</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mai's Theme</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.925</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>edm</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Stay With Me</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.439</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>rock</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Still Broke</td>\n",
       "      <td>Onra</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.477</td>\n",
       "      <td>edm</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Opening Credit</td>\n",
       "      <td>GoldLink</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.481</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>indietronica</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Have You Seen That Girl?</td>\n",
       "      <td>GoldLink</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.487</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Some Girl</td>\n",
       "      <td>GoldLink</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.95</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>edm</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Webbie Flow (U Like)</td>\n",
       "      <td>Isaiah Rashad</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.488</td>\n",
       "      <td>indietronica</td>\n",
       "      <td>pop</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ronnie Drake (feat. SZA)</td>\n",
       "      <td>Isaiah Rashad</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.681</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>house</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>West Savannah (feat. SZA)</td>\n",
       "      <td>Isaiah Rashad</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.772</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Brad Jordan (feat. Michael Da Vinci)</td>\n",
       "      <td>Isaiah Rashad</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.575</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Spice Girl</td>\n",
       "      <td>Aminé</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Turf</td>\n",
       "      <td>Aminé</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.32</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Mind's Eye Melody</td>\n",
       "      <td>Lone</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.7</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>downtempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Garden Shed</td>\n",
       "      <td>Tyler, The Creator</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.447</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>November</td>\n",
       "      <td>Tyler, The Creator</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.424</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Glitter</td>\n",
       "      <td>Tyler, The Creator</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.459</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Faust: Faust: Waltz</td>\n",
       "      <td>Charles Gounod</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.548</td>\n",
       "      <td>classical</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Glass Flows</td>\n",
       "      <td>Smino</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.724</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>house</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Innamission</td>\n",
       "      <td>Smino</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.534</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Music of the Air</td>\n",
       "      <td>Tim Hecker</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.397</td>\n",
       "      <td>classical</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>edm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>The Sequence</td>\n",
       "      <td>Bryson Tiller</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.525</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>r&amp;b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sorry Not Sorry</td>\n",
       "      <td>Bryson Tiller</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.594</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>pop</td>\n",
       "      <td>r&amp;b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>An Hour</td>\n",
       "      <td>Forest Swords</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.9</td>\n",
       "      <td>downtempo</td>\n",
       "      <td>indietronica</td>\n",
       "      <td>indietronica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name              artist  \\\n",
       "0                                                I Am         Jorja Smith   \n",
       "1                                           Eye 2 Eye         Huncho Jack   \n",
       "2                                          How U Feel         Huncho Jack   \n",
       "3                                            CINEMA 2        BROCKHAMPTON   \n",
       "4   Piano Concerto No.3 In C, Op.26: 1. Andante - ...    Sergei Prokofiev   \n",
       "5   Piano Concerto No.3 In C, Op.26: 2. Tema con v...    Sergei Prokofiev   \n",
       "6   Piano Concerto in G Major, M. 83: 2. Adagio assai       Maurice Ravel   \n",
       "7                    Gaspard de la nuit, M.55: Scarbo       Maurice Ravel   \n",
       "8   12 Sonates en trio, Op. 1, Sonate No. 2 in E M...     Antonio Vivaldi   \n",
       "9                                                Lush            Four Tet   \n",
       "10                                              Packs  The Underachievers   \n",
       "11                                 Meeker Warm Energy                Lone   \n",
       "12                                     Begin To Begin                Lone   \n",
       "13                                              Jaded                Lone   \n",
       "14                                         Pink Cloud       Little Dragon   \n",
       "15                                              Truth   Kamasi Washington   \n",
       "16                Belly of the Beast (feat. Chronixx)         Joey Bada$$   \n",
       "17                                             O.C.B.         Joey Bada$$   \n",
       "18                                               Drum          Slow Magic   \n",
       "19                                       What Happens            A$AP Mob   \n",
       "20                                               BANK        BROCKHAMPTON   \n",
       "21                                   Stardust (Intro)                 ZHU   \n",
       "22                               Will I See You Again                Onra   \n",
       "23                                     Fake Porcelain                Onra   \n",
       "24                                 Memories From 1968                Onra   \n",
       "25                                            Bye Bye                Onra   \n",
       "26                                           Gotta Go                Onra   \n",
       "27                                        Mai's Theme                Onra   \n",
       "28                                       Stay With Me                Onra   \n",
       "29                                        Still Broke                Onra   \n",
       "30                                     Opening Credit            GoldLink   \n",
       "31                           Have You Seen That Girl?            GoldLink   \n",
       "32                                          Some Girl            GoldLink   \n",
       "33                               Webbie Flow (U Like)       Isaiah Rashad   \n",
       "34                           Ronnie Drake (feat. SZA)       Isaiah Rashad   \n",
       "35                          West Savannah (feat. SZA)       Isaiah Rashad   \n",
       "36               Brad Jordan (feat. Michael Da Vinci)       Isaiah Rashad   \n",
       "37                                         Spice Girl               Aminé   \n",
       "38                                               Turf               Aminé   \n",
       "39                                  Mind's Eye Melody                Lone   \n",
       "40                                        Garden Shed  Tyler, The Creator   \n",
       "41                                           November  Tyler, The Creator   \n",
       "42                                            Glitter  Tyler, The Creator   \n",
       "43                                Faust: Faust: Waltz      Charles Gounod   \n",
       "44                                        Glass Flows               Smino   \n",
       "45                                        Innamission               Smino   \n",
       "46                                   Music of the Air          Tim Hecker   \n",
       "47                                       The Sequence       Bryson Tiller   \n",
       "48                                    Sorry Not Sorry       Bryson Tiller   \n",
       "49                                            An Hour       Forest Swords   \n",
       "\n",
       "   danceability energy loudness speechiness acousticness instrumentalness  \\\n",
       "0         0.714  0.775    0.341       0.327        0.137              0.0   \n",
       "1         0.663  0.842    0.208       0.101        0.003            0.001   \n",
       "2          0.72  0.725    0.199       0.052        0.008              0.0   \n",
       "3         0.856  0.712    0.318       0.062        0.163            0.031   \n",
       "4         0.737  0.429    0.513       0.078        0.632              0.0   \n",
       "5         0.312   0.26    0.905       0.038        0.967            0.863   \n",
       "6         0.341  0.189    1.028       0.038        0.981            0.856   \n",
       "7         0.414  0.003    1.726       0.058        0.993            0.922   \n",
       "8           0.9  0.365     0.32       0.235        0.147            0.185   \n",
       "9         0.626  0.758      0.2       0.243        0.022              0.0   \n",
       "10        0.468  0.756    0.483       0.043        0.005            0.903   \n",
       "11        0.745  0.672    0.611       0.118        0.009             0.78   \n",
       "12        0.532  0.274     0.96       0.428        0.137            0.755   \n",
       "13        0.673  0.514    0.781       0.046        0.042            0.781   \n",
       "14        0.404  0.677    0.288       0.073        0.031            0.057   \n",
       "15        0.533  0.581    0.486        0.03        0.032            0.004   \n",
       "16        0.731   0.71     0.25        0.29        0.534              0.0   \n",
       "17        0.526  0.894    0.245       0.389        0.137              0.0   \n",
       "18        0.861  0.574    0.628       0.056        0.001            0.871   \n",
       "19        0.782  0.549    0.393       0.495        0.201              0.0   \n",
       "20        0.385  0.564    1.089       0.171        0.881            0.819   \n",
       "21        0.521   0.55    0.311       0.071        0.003            0.171   \n",
       "22        0.445  0.569    0.347       0.103        0.019              0.0   \n",
       "23        0.723  0.495    0.512       0.102        0.226            0.887   \n",
       "24        0.399  0.551    0.426       0.162         0.24            0.723   \n",
       "25        0.498  0.716     0.37        0.14          0.0            0.905   \n",
       "26        0.591  0.919    0.228       0.386        0.034            0.293   \n",
       "27        0.367   0.95    0.275       0.546        0.014            0.425   \n",
       "28        0.563  0.451    0.583       0.056        0.158            0.499   \n",
       "29        0.395  0.689    0.343       0.035        0.012            0.825   \n",
       "30        0.336  0.387    0.362       0.028        0.496              0.0   \n",
       "31        0.583  0.654    0.323       0.395        0.605              0.0   \n",
       "32         0.78  0.773    0.376       0.462        0.447              0.0   \n",
       "33        0.533  0.743    0.334       0.096        0.871            0.847   \n",
       "34        0.703  0.835    0.223        0.27        0.227              0.0   \n",
       "35        0.482  0.779    0.244        0.27        0.356              0.0   \n",
       "36        0.741  0.775    0.379       0.362        0.386              0.0   \n",
       "37        0.941  0.323    0.515       0.506        0.176              0.0   \n",
       "38        0.679  0.405    0.461       0.246        0.685              0.0   \n",
       "39        0.788  0.495    0.344       0.256         0.04              0.0   \n",
       "40        0.543  0.572    0.449       0.338         0.51              0.0   \n",
       "41        0.401  0.532    0.578       0.508        0.103              0.0   \n",
       "42        0.547  0.759    0.352       0.413        0.354              0.0   \n",
       "43        0.308   0.34    0.862       0.046        0.892            0.917   \n",
       "44        0.579  0.555    0.443       0.742        0.602              0.0   \n",
       "45        0.716  0.382    0.458         0.3        0.313              0.0   \n",
       "46         0.16  0.067    0.954       0.039        0.621            0.653   \n",
       "47        0.671  0.655    0.472        0.22        0.451              0.0   \n",
       "48         0.61   0.66    0.278       0.104        0.192              0.0   \n",
       "49        0.489  0.709    0.533       0.066        0.726            0.756   \n",
       "\n",
       "   liveness valence  tempo     1st guess     2nd guess        actual  \n",
       "0     0.396    0.84   0.64       hip hop     downtempo           r&b  \n",
       "1     0.123   0.346  0.796       hip hop           edm       hip hop  \n",
       "2     0.137   0.202  0.715       hip hop           pop       hip hop  \n",
       "3     0.123   0.774  0.645         house           edm       hip hop  \n",
       "4     0.104   0.147    0.5       hip hop           r&b     classical  \n",
       "5     0.084   0.146  0.734          jazz    soundtrack     classical  \n",
       "6     0.328   0.095   0.66     classical    soundtrack     classical  \n",
       "7     0.055   0.056  0.332     classical     downtempo     classical  \n",
       "8     0.179   0.136  0.675       hip hop           r&b     classical  \n",
       "9      0.37   0.642    0.7       hip hop           r&b  indietronica  \n",
       "10    0.085   0.202    0.8          jazz    soundtrack       hip hop  \n",
       "11    0.175   0.482  0.595     downtempo         house     downtempo  \n",
       "12    0.074   0.074   0.58     downtempo       hip hop     downtempo  \n",
       "13    0.067   0.579    0.6     downtempo  indietronica     downtempo  \n",
       "14    0.112   0.617  0.773  indietronica           pop  indietronica  \n",
       "15    0.086   0.228   0.83     downtempo           edm          jazz  \n",
       "16    0.112   0.757  0.454       hip hop           r&b       hip hop  \n",
       "17    0.176   0.577  0.383       hip hop           r&b       hip hop  \n",
       "18    0.068   0.218  0.635         house           edm  indietronica  \n",
       "19    0.597   0.726  0.317       hip hop           r&b       hip hop  \n",
       "20    0.416   0.359  0.643    soundtrack  indietronica       hip hop  \n",
       "21    0.096   0.039   0.92       hip hop           edm           edm  \n",
       "22    0.374   0.537  0.457       hip hop           r&b     downtempo  \n",
       "23    0.106   0.197   0.73           pop  indietronica     downtempo  \n",
       "24    0.197   0.746  0.872       hip hop     downtempo     downtempo  \n",
       "25    0.618   0.761  1.018     downtempo       hip hop     downtempo  \n",
       "26    0.325   0.735  0.455     downtempo       hip hop     downtempo  \n",
       "27    0.848   0.668  0.925     downtempo           edm     downtempo  \n",
       "28    0.401   0.321  0.439     downtempo          rock     downtempo  \n",
       "29    0.252   0.129  0.477           edm    soundtrack     downtempo  \n",
       "30    0.975   0.059  0.481     downtempo  indietronica       hip hop  \n",
       "31    0.103   0.376  0.487       hip hop           r&b       hip hop  \n",
       "32    0.079   0.729   0.95       hip hop           edm       hip hop  \n",
       "33    0.759   0.743  0.488  indietronica           pop       hip hop  \n",
       "34    0.135   0.602  0.681       hip hop         house       hip hop  \n",
       "35    0.173   0.835  0.772       hip hop           r&b       hip hop  \n",
       "36    0.536   0.587  0.575       hip hop     downtempo       hip hop  \n",
       "37    0.205   0.662    0.6       hip hop           r&b       hip hop  \n",
       "38    0.166   0.452   0.32           r&b       hip hop       hip hop  \n",
       "39    0.108   0.357    0.7       hip hop           r&b     downtempo  \n",
       "40     0.28   0.569  0.447       hip hop           r&b       hip hop  \n",
       "41    0.478   0.413  0.424       hip hop     downtempo       hip hop  \n",
       "42    0.676   0.575  0.459       hip hop           r&b       hip hop  \n",
       "43    0.095   0.337  0.548     classical    soundtrack     classical  \n",
       "44    0.129   0.597  0.724       hip hop         house       hip hop  \n",
       "45    0.084    0.49  0.534       hip hop           r&b       hip hop  \n",
       "46    0.147   0.086  0.397     classical    soundtrack           edm  \n",
       "47    0.233   0.815  0.525       hip hop           r&b           r&b  \n",
       "48    0.107   0.419  0.594           r&b           pop           r&b  \n",
       "49    0.107   0.153    0.9     downtempo  indietronica  indietronica  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "result_data=[]\n",
    "\n",
    "def getGenre(index):\n",
    "    if index == len(full_genres):\n",
    "        return 'other'\n",
    "    return full_genres[index][0]\n",
    "\n",
    "for i in range(len(test_data.index.values)):\n",
    "    index = test_data.index.values[i]+1\n",
    "    result = []\n",
    "    result.append(songs[index][0])\n",
    "    result.append(songs[index][2])\n",
    "    x = np.array([features_test[i]])\n",
    "    for feature in x[0]:\n",
    "        result.append(round(feature,3))\n",
    "    y = np.array([targets_test[i]])\n",
    "    prediction = model.predict(x)\n",
    "\n",
    "    first = [-1,-1]\n",
    "    second = [-2, -2]\n",
    "    for j,guess in enumerate(prediction[0]):\n",
    "        if guess > first[1]:\n",
    "            second = first\n",
    "            first = [j,guess]\n",
    "        elif guess > second[1]:\n",
    "            second = [j,guess]\n",
    "    result.append(getGenre(first[0]))\n",
    "    result.append(getGenre(second[0]))\n",
    "    result.append(getGenre(songs[index][-1][0]))\n",
    "    result_data.append(result)\n",
    "\n",
    "result_array = np.array(result_data)\n",
    "\n",
    "column_names_results= ['name','artist','danceability','energy','loudness','speechiness',\n",
    "          'acousticness','instrumentalness','liveness','valence','tempo','1st guess', '2nd guess','actual']    \n",
    "\n",
    "rf = pd.DataFrame(data=result_array[0:,0:],\n",
    "                 columns=column_names_results)\n",
    "rf[:50]\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', 14):\n",
    "#     display(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c859c30fe91d44aead573640e6daf654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='danceability', max=1.0), FloatSlider(value=0.0, description='energy', max=1.0), FloatSlider(value=0.0, description='loudness', max=1.0), FloatSlider(value=0.0, description='speechiness', max=1.0), FloatSlider(value=0.0, description='acousticness', max=1.0), FloatSlider(value=0.0, description='instrumentalness', max=1.0), FloatSlider(value=0.0, description='liveness', max=1.0), FloatSlider(value=0.0, description='valence', max=1.0), FloatSlider(value=0.0, description='tempo', max=1.0), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def f(danceability, energy,\n",
    "     loudness, speechiness,\n",
    "     acousticness, instrumentalness,\n",
    "     liveness, valence,\n",
    "     tempo):\n",
    "    \n",
    "    x = np.array([[danceability, energy, loudness, speechiness, acousticness, \n",
    "                  instrumentalness, liveness, valence,tempo]])\n",
    "    prediction = model.predict(x)\n",
    "\n",
    "    first = [-1,-1]\n",
    "    second = [-2, -2]\n",
    "    for j,guess in enumerate(prediction[0]):\n",
    "        if guess > first[1]:\n",
    "            second = first\n",
    "            first = [j,guess]\n",
    "        elif guess > second[1]:\n",
    "            second = [j,guess]\n",
    "            \n",
    "    first_guess = getGenre(first[0])\n",
    "    second_guess = getGenre(second[0])\n",
    "    \n",
    "    display(first_guess,second_guess)\n",
    "    return first_guess\n",
    "\n",
    "w = interactive(f, danceability=(0,1,0.1),\n",
    "                energy=(0,1,0.1),\n",
    "                loudness=(0,1,0.1),\n",
    "                speechiness=(0,1,0.1),\n",
    "                acousticness=(0,1,0.1),\n",
    "                instrumentalness=(0,1,0.1),\n",
    "                liveness=(0,1,0.1),\n",
    "                valence=(0,1,0.1),\n",
    "                tempo=(0,1,0.1))\n",
    "display(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
